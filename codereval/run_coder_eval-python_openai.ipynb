{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import general_adapter\n",
    "from openai import OpenAI\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    file_path_base = 'CoderEval4Python.json'\n",
    "    file_path_label = 'CEPythonHumanLabel.jsonl'\n",
    "\n",
    "    # prompt stuff\n",
    "    prompt_num = 10\n",
    "\n",
    "    # model stuff\n",
    "    model = 'gpt-4-turbo'\n",
    "    key = ''\n",
    "\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset and Print Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open(args.file_path_base, 'r') as file:\n",
    "    df_base = pd.json_normalize(pd.read_json(file)['RECORDS'])\n",
    "\n",
    "df_label = pd.read_json(args.file_path_label, lines=True)\n",
    "\n",
    "print(df_base.columns)\n",
    "print(df_label.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter Dataframes To Only Include All Self-Contained Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncate df_base to only include prompts with level as \"self_contained\"\n",
    "df_base_filtered = df_base[df_base['level'] == 'self_contained']\n",
    "# reset index\n",
    "df_base_filtered.reset_index(drop=True, inplace=True)\n",
    "print(df_base_filtered.shape)\n",
    "# saved all the question_ids in df_base_filtered to a list\n",
    "self_contained_ids = df_base_filtered['_id'].tolist()\n",
    "\n",
    "for i in range(len(self_contained_ids)):\n",
    "    print(self_contained_ids[i])\n",
    "    \n",
    "# filter df_label to only include rows with question_id in question_ids\n",
    "df_label_filtered = df_label[df_label['question_id'].isin(self_contained_ids)]\n",
    "# reset index\n",
    "df_label_filtered.reset_index(drop=True, inplace=True)\n",
    "print(df_label_filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print Content of Selected Prompt (DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df_base.columns:\n",
    "#     print(f'{col}: {df_base[col][args.prompt_num]}')\n",
    "\n",
    "for col in df_label_filtered.columns:\n",
    "    print(f'{col}: {df_label_filtered[col][args.prompt_num]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing Delta Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_header = df_label_filtered['signature'][args.prompt_num]\n",
    "docstring = df_label_filtered['docstring'][args.prompt_num]\n",
    "print('Prompt: ', args.prompt_num)\n",
    "print('-'*50)\n",
    "print('FUNCTION HEADER')\n",
    "print(function_header)\n",
    "print('-'*50)\n",
    "print('DOCSTRING')\n",
    "print(docstring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Deltas (Combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"\\bdef\\s+(\\w+)\\s*\\(([^)]*)\\)(\\s*->\\s*[\\w\\[\\],\\s]*)?\\s*:\"\n",
    "\n",
    "def extract_entry_point(function_header):\n",
    "    return re.search(pattern, function_header).group(1)\n",
    "\n",
    "def normalized_function_header(function_header):\n",
    "    entry_point = extract_entry_point(function_header)\n",
    "    return re.sub(entry_point, \"func\", function_header)\n",
    "\n",
    "def del_underscore_and_caps(entry_point):\n",
    "    if '_' in entry_point:\n",
    "        func_elements = entry_point.split('_')\n",
    "        func_elements = [i.capitalize() for i in func_elements]\n",
    "        func_elements = ''.join(func_elements)\n",
    "        return func_elements\n",
    "    return entry_point.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deltas(function_header, docstring):\n",
    "    deltas_dict = {}\n",
    "\n",
    "    # Pre-Transfromation Deltas\n",
    "    deltas_dict['delta_1'] = f'{function_header}\\n\"\"\"\\n{docstring}\\n\"\"\"\\n'\n",
    "    deltas_dict['delta_2'] = f'{docstring}\\nCreate a function named {extract_entry_point(function_header)}'\n",
    "    deltas_dict['delta_3'] = f'{normalized_function_header(function_header)}\\n\"\"\"\\n{docstring}\\n\"\"\"\\n'\n",
    "    # deltas_dict['delta_4'] = f'{docstring}\\n{function_header}'\n",
    "    deltas_dict['delta_4'] = f'{function_header}'\n",
    "\n",
    "    # Post-Transformation Deltas\n",
    "    docstring_transform = docstring.title() # capitalize the first letter of each word in the docstring\n",
    "    deadcode_transform = f'{function_header}\\n\\tif False:\\n\\t\\tx=[_ for i in range(42)]' # add a line of code to the function\n",
    "    entry_point_transform = del_underscore_and_caps(extract_entry_point(function_header)) # transform the function name\n",
    "    entry_point_function_header_transform = function_header.replace(extract_entry_point(function_header), entry_point_transform) # replace the function name with a new name\n",
    "    entry_point_docstring_transform = docstring.replace(extract_entry_point(function_header), entry_point_transform) # replace the function name with a new name\n",
    "\n",
    "    deltas_dict['delta_5'] = f'{function_header}\\n\"\"\"\\n{docstring_transform}\\n\"\"\"\\n'\n",
    "    deltas_dict['delta_6'] = f'{deadcode_transform}\\n\"\"\"\\n{docstring}\\n\"\"\"\\n'\n",
    "    deltas_dict['delta_7'] = f'{entry_point_function_header_transform}\\n\"\"\"\\n{entry_point_docstring_transform}\\n\"\"\"\\n'\n",
    "    \n",
    "    # New Deltas\n",
    "    prefix_docstring = f'DOCSTRING: {docstring}'\n",
    "    entry_point = extract_entry_point(function_header)\n",
    "    prefix_entry_point = f'func_{entry_point}'\n",
    "    function_header_prefix = function_header.replace(entry_point, prefix_entry_point)\n",
    "    deltas_dict['delta_8'] = f'{function_header}\\n\"\"\"\\n{prefix_docstring}\\n\"\"\"\\n'\n",
    "    deltas_dict['delta_9'] = f'{function_header_prefix}\\n\"\"\"\\n{docstring.replace(entry_point, prefix_entry_point)}\\n\"\"\"\\n'\n",
    "    \n",
    "    return deltas_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM Inference Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_openai_output(delta):\n",
    "    question = f\"{delta}\"\n",
    "    client = OpenAI(api_key=args.key)\n",
    "    response = client.chat.completions.create(\n",
    "        model=args.model,\n",
    "        messages=[{'role': 'user', 'content': question}],\n",
    "        max_tokens=2048,\n",
    "        temperature=0\n",
    "    )\n",
    "    answer = response.choices[0].message.content.strip()\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_deltas = pd.DataFrame(columns=['_id', 'delta_num', 'delta_val'])\n",
    "\n",
    "for i in range(len(df_label_filtered)):\n",
    "    id = self_contained_ids[i]\n",
    "    function_header = df_label_filtered['signature'][i]\n",
    "    docstring = df_label_filtered['docstring'][i]\n",
    "    deltas_dict = create_deltas(function_header, docstring)\n",
    "    row1 = pd.DataFrame([{'_id': id, 'delta_num': '8', 'delta_val': deltas_dict['delta_8']}])\n",
    "    row2 = pd.DataFrame([{'_id': id, 'delta_num': '9', 'delta_val': deltas_dict['delta_9']}])\n",
    "    df_new_deltas = pd.concat([df_new_deltas, row1], ignore_index=True)\n",
    "    df_new_deltas = pd.concat([df_new_deltas, row2], ignore_index=True)\n",
    "\n",
    "# export the new deltas to a jsonl file\n",
    "df_new_deltas.to_json('codereval-python_delta8_delta9.jsonl', orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate LLM Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns=['prompt', 'delta', 'code', 'llm_output'])\n",
    "\n",
    "for prompt_index in range(df_label_filtered.shape[0]):\n",
    "    print(f'Prompt: {prompt_index}')\n",
    "    function_header = df_label_filtered['signature'][prompt_index]\n",
    "    docstring = df_label_filtered['docstring'][prompt_index]\n",
    "    deltas_dict = create_deltas(function_header, docstring)\n",
    "\n",
    "    # temporary: remove all deltas except delta_8 and delta_9\n",
    "    deltas_dict = {key: deltas_dict[key] for key in ['delta_8', 'delta_9']}\n",
    "\n",
    "    for delta_index, delta in enumerate(deltas_dict):\n",
    "        print(f\"Generating Output for Delta {delta_index + 1} of {len(deltas_dict)}\")\n",
    "        llm_output = generate_openai_output(deltas_dict[delta])\n",
    "        code = general_adapter.extract_python_code(llm_output)\n",
    "        row = pd.DataFrame([{'prompt': prompt_index, 'delta': delta, 'code': code, 'llm_output': llm_output}])\n",
    "        df_results = pd.concat([df_results, row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Results to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to JSONL file\n",
    "df_results.to_json(f\"{args.model}_codereval-python_delta8_delta9.jsonl\", orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdfc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
